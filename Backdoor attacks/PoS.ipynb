{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pvM0jm_PaR8"
      },
      "source": [
        "###Imports and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-19T17:07:40.710946Z",
          "iopub.status.busy": "2025-06-19T17:07:40.710785Z",
          "iopub.status.idle": "2025-06-19T17:07:47.663792Z",
          "shell.execute_reply": "2025-06-19T17:07:47.663054Z",
          "shell.execute_reply.started": "2025-06-19T17:07:40.710932Z"
        },
        "id": "vO_yewVqPcUU",
        "outputId": "3fbd0be3-fdee-4be3-cb36-65ad3306870d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flexBlock in /home/mario/jupyter-env/lib/python3.12/site-packages (0.0.1)\n",
            "Requirement already satisfied: flexclash in /home/mario/jupyter-env/lib/python3.12/site-packages (0.0.3)\n",
            "Requirement already satisfied: pytorch-lightning in /home/mario/jupyter-env/lib/python3.12/site-packages (2.5.2)\n",
            "Requirement already satisfied: flexible-fl in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexBlock) (0.7.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch-lightning) (2.7.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.5.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch-lightning) (1.7.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch-lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch-lightning) (4.14.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch-lightning) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.12.14)\n",
            "Requirement already satisfied: setuptools in /home/mario/jupyter-env/lib/python3.12/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (80.9.0)\n",
            "Requirement already satisfied: filelock in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.3.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.3.1)\n",
            "Requirement already satisfied: multiprocess in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexible-fl->flexBlock) (0.70.18)\n",
            "Requirement already satisfied: scikit-learn in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexible-fl->flexBlock) (1.7.0)\n",
            "Requirement already satisfied: cardinality in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexible-fl->flexBlock) (0.1.1)\n",
            "Requirement already satisfied: sultan in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexible-fl->flexBlock) (0.9.1)\n",
            "Requirement already satisfied: scipy in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexible-fl->flexBlock) (1.16.0)\n",
            "Requirement already satisfied: gdown in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexible-fl->flexBlock) (5.2.0)\n",
            "Requirement already satisfied: tensorly in /home/mario/jupyter-env/lib/python3.12/site-packages (from flexible-fl->flexBlock) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mario/jupyter-env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/mario/jupyter-env/lib/python3.12/site-packages (from gdown->flexible-fl->flexBlock) (4.13.4)\n",
            "Requirement already satisfied: requests[socks] in /home/mario/jupyter-env/lib/python3.12/site-packages (from gdown->flexible-fl->flexBlock) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: dill>=0.4.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from multiprocess->flexible-fl->flexBlock) (0.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from scikit-learn->flexible-fl->flexBlock) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from scikit-learn->flexible-fl->flexBlock) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from beautifulsoup4->gdown->flexible-fl->flexBlock) (2.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from requests[socks]->gdown->flexible-fl->flexBlock) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from requests[socks]->gdown->flexible-fl->flexBlock) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mario/jupyter-env/lib/python3.12/site-packages (from requests[socks]->gdown->flexible-fl->flexBlock) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mario/jupyter-env/lib/python3.12/site-packages (from requests[socks]->gdown->flexible-fl->flexBlock) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install flexBlock flexclash pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-19T17:07:47.665854Z",
          "iopub.status.busy": "2025-06-19T17:07:47.665600Z",
          "iopub.status.idle": "2025-06-19T17:07:58.791527Z",
          "shell.execute_reply": "2025-06-19T17:07:58.790937Z",
          "shell.execute_reply.started": "2025-06-19T17:07:47.665830Z"
        },
        "id": "VxXzOWn-PVaN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import copy\n",
        "import tensorly as tl\n",
        "import torchvision\n",
        "from functools import partial\n",
        "from flex.data import Dataset, FedDataDistribution, FedDatasetConfig\n",
        "from flex.model import FlexModel\n",
        "from flex.pool import FlexPool, collect_clients_weights, fed_avg, init_server_model\n",
        "from flexBlock.blockchain.blockchain import BlockchainPoFL, BlockPoFL\n",
        "from flexBlock.pool.primitives import collect_to_send_wrapper\n",
        "from flexclash.data import data_poisoner\n",
        "from flexclash.pool import multikrum, trimmed_mean\n",
        "from PIL import Image\n",
        "from flex.pool.aggregators import set_tensorly_backend\n",
        "from flex.pool.decorators import (\n",
        "    aggregate_weights,\n",
        "    collect_clients_weights,\n",
        "    deploy_server_model,\n",
        "    set_aggregated_weights,\n",
        ")\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import ResNet18_Weights, resnet18, MobileNet_V2_Weights, mobilenet_v2, EfficientNet_B0_Weights, efficientnet_b0\n",
        "from tqdm import tqdm\n",
        "from pytorch_lightning import seed_everything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhuJ-EDML1FK"
      },
      "source": [
        "###Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-19T17:07:58.792523Z",
          "iopub.status.busy": "2025-06-19T17:07:58.792182Z",
          "iopub.status.idle": "2025-06-19T17:08:18.317790Z",
          "shell.execute_reply": "2025-06-19T17:08:18.317168Z",
          "shell.execute_reply.started": "2025-06-19T17:07:58.792505Z"
        },
        "id": "DnlGN-CWPtqs",
        "outputId": "ab671861-782a-4139-d6e0-06549e709596",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N_CLIENTS = 20\n",
        "N_POISONED = 4\n",
        "LOCAL_EPOCHS = 1\n",
        "N_POOLS = 5 # == N_MINERS\n",
        "N_ROUNDS = 15\n",
        "NON_IID_RATE = 0.5\n",
        "POISONING_RATE = 0.1\n",
        "\n",
        "# ========== MODEL/DATASET CONFIG ==========\n",
        "MODEL_NAME = \"resnet18\"  # Options: \"resnet18\", \"efficientnet\", \"mobilenet\"\n",
        "DATASET_NAME = \"GTSRB\"   # Options: \"MNIST\", \"CIFAR10\", \"GTSRB\"\n",
        "TRIGGER = \"wanet\"  # Options: \"square\", \"wanet\"\n",
        "AGG_FUNCTION = \"krum\"  # Options: \"fed_avg\", \"krum\"\n",
        "# =================================\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "seed_everything(SEED) #Â reproducibility "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVZZdIo35vkS",
        "outputId": "b32990ef-408a-4c39-aa3c-c83f697af092"
      },
      "outputs": [],
      "source": [
        "if MODEL_NAME == \"resnet18\":\n",
        "     data_transforms = ResNet18_Weights.DEFAULT.transforms()\n",
        "     LR = 0.00005\n",
        "\n",
        "elif MODEL_NAME == \"mobilenet\":\n",
        "     data_transforms = MobileNet_V2_Weights.DEFAULT.transforms()\n",
        "     LR = 0.0001\n",
        "\n",
        "elif MODEL_NAME == \"efficientnet\":\n",
        "    data_transforms = EfficientNet_B0_Weights.DEFAULT.transforms()\n",
        "    LR = 0.0001\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Unknown model {MODEL_NAME}\")\n",
        "\n",
        "\n",
        "if AGG_FUNCTION == \"fed_avg\":\n",
        "    agg_function = fed_avg\n",
        "elif AGG_FUNCTION == \"krum\":\n",
        "    agg_function = partial(multikrum, f=0, m=3)   # We use multikrum with that protect up to f=1 malicious clients and selects m=2 clients for aggregation\n",
        "    agg_function.__name__ = \"krum\"\n",
        "\n",
        "\n",
        "if DATASET_NAME == \"MNIST\":\n",
        "    NUM_CLASSES = 10\n",
        "    \n",
        "    train_data = datasets.MNIST(root=\".\", train=True, download=True, transform=None)\n",
        "    test_data = datasets.MNIST(root=\".\", train=False, download=True, transform=None)\n",
        "\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.Resize(224),  # ResNet18 expects 224x224 input; adjust as needed\n",
        "        transforms.Lambda(lambda x: x.convert(\"RGB\")),  # Convert to 3 channels\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet means/stds, suitable for ResNet18\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "    POISON_PIXELS = 4\n",
        "\n",
        "elif DATASET_NAME == \"CIFAR10\":\n",
        "    NUM_CLASSES = 10\n",
        "    train_data = datasets.CIFAR10(root=\".\", train=True, download=True, transform=None)\n",
        "    test_data = datasets.CIFAR10(root=\".\", train=False, download=True, transform=None)\n",
        "\n",
        "    POISON_PIXELS = 4\n",
        "\n",
        "elif DATASET_NAME == \"GTSRB\":\n",
        "    NUM_CLASSES = 43\n",
        "    train_data = datasets.GTSRB(root=\".\", split=\"train\", download=True, transform=None)\n",
        "    test_data = datasets.GTSRB(root=\".\", split=\"test\", download=True, transform=None)\n",
        "\n",
        "    POISON_PIXELS = 12\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Unknown dataset\")\n",
        "\n",
        "\n",
        "test_data = Dataset.from_torchvision_dataset(test_data)\n",
        "\n",
        "val_size = int(len(test_data)*0.2)\n",
        "val_data, test_data = test_data[:val_size], test_data[val_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "inK7FXvL5sNq"
      },
      "outputs": [],
      "source": [
        "# Distribute clients across pools\n",
        "client_distributions = np.array_split(np.random.permutation(np.arange(N_CLIENTS)), N_POOLS)\n",
        "\n",
        "# Gets labels for all datasets\n",
        "def get_labels(dataset):\n",
        "    if hasattr(dataset, 'targets'):\n",
        "        return np.array(dataset.targets)\n",
        "    elif hasattr(dataset, '_labels'):\n",
        "        return np.array(dataset._labels)\n",
        "    elif hasattr(dataset, '_samples'):\n",
        "        return np.array([label for _, label in dataset._samples])\n",
        "\n",
        "DATA_LABELS = get_labels(train_data)\n",
        "\n",
        "def dirichlet_distribution_split_per_client(dataset, n_clients, alpha=NON_IID_RATE):\n",
        "    y = DATA_LABELS\n",
        "    num_classes = len(np.unique(y))\n",
        "\n",
        "    class_proportions = torch.distributions.Dirichlet(torch.tensor([alpha] * n_clients)).sample([num_classes]).numpy()\n",
        "\n",
        "    split_indices = [[] for _ in range(n_clients)]\n",
        "\n",
        "    # Split data by class\n",
        "    for class_idx in range(num_classes):\n",
        "        class_indices = np.where(y == class_idx)[0]\n",
        "        np.random.shuffle(class_indices)\n",
        "\n",
        "        class_sample_sizes = (class_proportions[class_idx] * len(class_indices)).astype(int)\n",
        "        class_sample_sizes[-1] = len(class_indices) - np.sum(class_sample_sizes[:-1])\n",
        "\n",
        "        start_idx = 0\n",
        "        for client_idx, n_samples in enumerate(class_sample_sizes):\n",
        "            split_indices[client_idx].extend(class_indices[start_idx:start_idx + n_samples].tolist())\n",
        "            start_idx += n_samples\n",
        "\n",
        "    #Shuffles local client data indices, otherwise all classes are separated in the datasets\n",
        "    for client_indices in split_indices:\n",
        "        np.random.shuffle(client_indices)\n",
        "\n",
        "    pool_indices = []\n",
        "    for pool_client_indices in client_distributions:\n",
        "        pool_client_data = [split_indices[i] for i in pool_client_indices]\n",
        "        pool_indices.append(pool_client_data)\n",
        "\n",
        "    return pool_indices\n",
        "\n",
        "# Creates a non-IID setup with dirichclet distribution\n",
        "miners_indices = dirichlet_distribution_split_per_client(train_data, N_CLIENTS)\n",
        "\n",
        "# Creates the local datasets for each pool\n",
        "flex_miners_data = []\n",
        "for n in range(N_POOLS):\n",
        "\n",
        "    config = FedDatasetConfig(\n",
        "        seed=SEED,\n",
        "        n_nodes=len(client_distributions[n]),\n",
        "        indexes_per_node=miners_indices[n],\n",
        "        replacement=False\n",
        "    )\n",
        "\n",
        "    # Federated dataset for this pool\n",
        "    flex_dataset = FedDataDistribution.from_config(\n",
        "        centralized_data=Dataset.from_torchvision_dataset(train_data),\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    flex_miners_data.append(flex_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-19T17:08:18.318815Z",
          "iopub.status.busy": "2025-06-19T17:08:18.318593Z",
          "iopub.status.idle": "2025-06-19T17:08:21.506385Z",
          "shell.execute_reply": "2025-06-19T17:08:21.505792Z",
          "shell.execute_reply.started": "2025-06-19T17:08:18.318798Z"
        },
        "id": "Kz-JK2ga6EaF",
        "outputId": "b5c72b7c-e4a9-4af6-ddde-af3bd4837cf7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Client 0 (Miner 0, Local Client 0) data: {0: 19, 1: 14, 2: 8, 3: 25, 4: 46, 5: 43, 6: 9, 7: 17, 8: 26, 9: 45, 10: 24, 12: 37, 13: 6, 14: 26, 15: 67, 16: 12, 17: 17, 18: 2, 19: 10, 21: 1, 22: 16, 23: 1, 24: 2, 25: 80, 26: 2, 28: 7, 29: 3, 30: 34, 31: 62, 32: 1, 33: 5, 34: 36, 35: 25, 36: 11, 37: 4, 38: 43, 39: 19, 40: 23, 41: 15, 42: 20}\n",
            " - Total number of samples: 863\n",
            "Client 17 (Miner 0, Local Client 1) data: {0: 2, 1: 31, 2: 8, 3: 54, 4: 29, 5: 316, 6: 3, 7: 133, 8: 40, 9: 49, 10: 105, 11: 36, 12: 49, 13: 3, 14: 7, 15: 27, 17: 12, 18: 39, 19: 11, 20: 21, 21: 4, 22: 28, 23: 1, 24: 23, 25: 93, 26: 2, 28: 5, 30: 10, 32: 20, 33: 55, 34: 3, 35: 49, 38: 46, 39: 10, 41: 20, 42: 12}\n",
            " - Total number of samples: 1356\n",
            "Client 15 (Miner 0, Local Client 2) data: {0: 2, 1: 263, 2: 4, 3: 2, 4: 45, 5: 8, 7: 13, 8: 129, 9: 7, 10: 18, 11: 196, 12: 93, 13: 198, 14: 10, 15: 4, 16: 5, 17: 5, 18: 45, 19: 1, 20: 5, 21: 69, 22: 26, 23: 1, 25: 54, 26: 7, 27: 3, 28: 1, 29: 7, 30: 25, 31: 71, 34: 32, 35: 10, 36: 79, 37: 6, 38: 144, 39: 35, 40: 4, 41: 7, 42: 2}\n",
            " - Total number of samples: 1636\n",
            "Client 1 (Miner 0, Local Client 3) data: {0: 3, 1: 4, 2: 3, 3: 63, 4: 205, 5: 42, 6: 22, 7: 16, 8: 1, 9: 3, 10: 48, 11: 35, 12: 11, 13: 356, 14: 8, 15: 24, 16: 12, 17: 135, 18: 219, 20: 2, 22: 2, 23: 58, 24: 19, 25: 22, 26: 34, 27: 2, 28: 12, 29: 2, 30: 41, 31: 84, 32: 9, 33: 21, 34: 20, 35: 79, 37: 1, 38: 40, 39: 8, 40: 46, 41: 25, 42: 1}\n",
            " - Total number of samples: 1738\n",
            "Client 8 (Miner 1, Local Client 0) data: {0: 65, 2: 24, 3: 33, 4: 255, 5: 92, 6: 2, 8: 73, 9: 62, 10: 7, 11: 211, 12: 59, 13: 7, 14: 12, 15: 11, 16: 6, 17: 1, 20: 5, 21: 49, 22: 27, 23: 36, 24: 1, 25: 74, 26: 23, 27: 11, 28: 24, 30: 18, 31: 14, 35: 65, 36: 2, 38: 19, 39: 5, 41: 10, 42: 24}\n",
            " - Total number of samples: 1327\n",
            "Client 5 (Miner 1, Local Client 1) data: {0: 5, 1: 4, 2: 217, 4: 7, 5: 5, 6: 1, 9: 13, 10: 2, 11: 46, 12: 7, 13: 72, 14: 44, 15: 2, 16: 1, 18: 17, 20: 2, 22: 3, 23: 8, 24: 3, 25: 37, 28: 4, 29: 38, 30: 6, 32: 23, 33: 148, 34: 71, 35: 171, 36: 82, 37: 2, 38: 16, 40: 1, 42: 11}\n",
            " - Total number of samples: 1069\n",
            "Client 11 (Miner 1, Local Client 2) data: {0: 3, 1: 175, 3: 5, 4: 45, 5: 24, 7: 56, 8: 14, 9: 1, 10: 135, 11: 39, 12: 20, 14: 17, 15: 21, 16: 12, 17: 5, 18: 15, 19: 3, 20: 5, 23: 2, 24: 46, 25: 170, 26: 23, 27: 30, 28: 15, 29: 1, 31: 32, 32: 2, 33: 11, 34: 1, 36: 2, 38: 55, 39: 3, 40: 59, 41: 7, 42: 10}\n",
            " - Total number of samples: 1064\n",
            "Client 3 (Miner 1, Local Client 3) data: {0: 8, 1: 72, 2: 19, 3: 18, 4: 124, 5: 90, 6: 2, 7: 453, 8: 52, 9: 224, 12: 157, 13: 46, 14: 14, 15: 50, 16: 12, 17: 5, 18: 50, 19: 10, 21: 28, 22: 6, 23: 2, 24: 31, 25: 22, 26: 70, 27: 55, 28: 20, 30: 1, 31: 1, 33: 41, 34: 12, 35: 26, 36: 6, 37: 1, 38: 5, 39: 1, 40: 1, 41: 11, 42: 15}\n",
            " - Total number of samples: 1761\n",
            "Client 18 (Miner 2, Local Client 0) data: {0: 3, 1: 119, 2: 223, 3: 5, 4: 16, 5: 80, 6: 22, 7: 24, 8: 3, 9: 66, 10: 118, 11: 3, 12: 42, 13: 128, 14: 1, 15: 17, 16: 14, 18: 72, 19: 2, 20: 19, 22: 26, 23: 10, 25: 19, 26: 52, 29: 5, 31: 3, 32: 5, 33: 15, 35: 28, 37: 75, 38: 209, 39: 34, 40: 3, 41: 1}\n",
            " - Total number of samples: 1462\n",
            "Client 16 (Miner 2, Local Client 1) data: {0: 1, 1: 18, 2: 68, 4: 10, 5: 156, 6: 5, 7: 17, 8: 14, 9: 370, 10: 171, 11: 35, 12: 189, 13: 50, 14: 1, 15: 40, 17: 9, 19: 1, 20: 5, 21: 1, 22: 12, 23: 45, 24: 8, 25: 101, 26: 4, 27: 10, 28: 21, 29: 7, 30: 54, 31: 16, 32: 17, 34: 5, 35: 17, 36: 23, 38: 57, 39: 5, 40: 2, 42: 8}\n",
            " - Total number of samples: 1573\n",
            "Client 13 (Miner 2, Local Client 2) data: {1: 20, 4: 11, 5: 96, 6: 12, 7: 91, 8: 71, 9: 27, 10: 26, 11: 1, 13: 17, 14: 68, 16: 1, 18: 57, 19: 11, 20: 2, 22: 12, 23: 6, 24: 4, 25: 117, 26: 8, 27: 1, 28: 62, 29: 10, 31: 45, 33: 9, 34: 16, 35: 15, 36: 1, 37: 21, 38: 1, 39: 37, 40: 3, 41: 15, 42: 4}\n",
            " - Total number of samples: 898\n",
            "Client 2 (Miner 2, Local Client 3) data: {1: 55, 2: 233, 3: 5, 4: 119, 6: 7, 8: 47, 9: 19, 10: 107, 11: 1, 12: 30, 14: 177, 15: 3, 16: 1, 17: 16, 18: 157, 19: 7, 20: 64, 21: 2, 22: 3, 23: 90, 25: 2, 26: 36, 28: 6, 29: 5, 31: 23, 32: 4, 33: 5, 34: 8, 35: 8, 36: 2, 38: 94, 39: 15, 40: 5, 41: 2}\n",
            " - Total number of samples: 1358\n",
            "Client 9 (Miner 3, Local Client 0) data: {0: 12, 1: 184, 2: 4, 3: 77, 4: 3, 5: 70, 6: 11, 10: 105, 11: 13, 12: 199, 14: 4, 15: 8, 16: 2, 17: 325, 18: 71, 19: 4, 21: 6, 22: 9, 23: 11, 24: 9, 25: 2, 26: 20, 27: 1, 28: 25, 29: 3, 30: 1, 31: 1, 32: 2, 33: 37, 34: 8, 36: 1, 37: 2, 38: 177, 40: 1, 41: 5, 42: 25}\n",
            " - Total number of samples: 1438\n",
            "Client 19 (Miner 3, Local Client 1) data: {0: 9, 1: 45, 2: 67, 3: 11, 4: 46, 5: 22, 6: 64, 7: 28, 8: 11, 9: 11, 10: 26, 11: 23, 12: 176, 13: 52, 14: 39, 15: 9, 16: 116, 17: 56, 18: 14, 19: 45, 20: 9, 21: 35, 22: 24, 23: 27, 24: 14, 25: 99, 26: 27, 27: 19, 28: 21, 29: 10, 30: 11, 31: 12, 32: 20, 33: 26, 34: 21, 35: 93, 36: 13, 37: 10, 38: 116, 39: 30, 40: 25, 41: 10, 42: 10}\n",
            " - Total number of samples: 1552\n",
            "Client 4 (Miner 3, Local Client 2) data: {1: 163, 2: 285, 3: 610, 4: 2, 5: 45, 6: 8, 7: 20, 8: 42, 10: 134, 11: 155, 12: 4, 13: 26, 14: 9, 15: 31, 16: 1, 17: 40, 18: 1, 19: 2, 20: 6, 21: 11, 22: 2, 24: 1, 25: 5, 26: 7, 27: 4, 28: 28, 29: 10, 30: 47, 31: 22, 32: 9, 33: 2, 35: 9, 36: 2, 37: 14, 38: 77, 40: 43, 42: 22}\n",
            " - Total number of samples: 1899\n",
            "Client 12 (Miner 3, Local Client 3) data: {1: 27, 2: 265, 3: 15, 4: 41, 5: 12, 6: 1, 7: 29, 8: 6, 9: 21, 10: 7, 11: 2, 13: 29, 14: 80, 15: 25, 17: 71, 18: 40, 19: 12, 21: 28, 22: 32, 23: 37, 25: 101, 26: 1, 27: 7, 29: 20, 30: 7, 31: 15, 32: 4, 33: 6, 34: 1, 35: 127, 36: 5, 37: 8, 38: 1, 40: 4, 41: 1}\n",
            " - Total number of samples: 1088\n",
            "Client 7 (Miner 4, Local Client 0) data: {0: 7, 1: 119, 2: 36, 3: 10, 4: 89, 5: 15, 6: 1, 7: 39, 8: 144, 9: 7, 10: 127, 11: 24, 13: 178, 14: 7, 15: 2, 16: 21, 17: 1, 19: 2, 20: 15, 21: 1, 22: 31, 25: 7, 26: 18, 27: 12, 28: 68, 30: 10, 31: 51, 33: 10, 34: 33, 35: 19, 36: 18, 38: 2, 39: 7, 41: 25, 42: 4}\n",
            " - Total number of samples: 1160\n",
            "Client 10 (Miner 4, Local Client 1) data: {0: 8, 1: 171, 2: 4, 3: 2, 4: 29, 5: 15, 6: 18, 7: 20, 9: 38, 10: 3, 12: 57, 13: 266, 14: 3, 15: 40, 16: 42, 17: 4, 18: 10, 19: 6, 20: 5, 24: 7, 25: 8, 26: 16, 27: 12, 28: 14, 29: 4, 32: 61, 33: 30, 34: 9, 35: 33, 36: 9, 37: 2, 40: 3, 41: 6, 42: 5}\n",
            " - Total number of samples: 960\n",
            "Client 14 (Miner 4, Local Client 2) data: {0: 2, 1: 14, 2: 18, 3: 17, 4: 20, 5: 24, 6: 32, 7: 2, 8: 51, 9: 2, 10: 107, 11: 73, 12: 265, 13: 5, 14: 1, 15: 34, 16: 5, 17: 12, 18: 1, 19: 1, 20: 75, 21: 1, 22: 10, 23: 21, 24: 8, 25: 3, 26: 16, 27: 12, 28: 19, 29: 21, 31: 47, 33: 53, 34: 21, 35: 16, 36: 11, 38: 259, 40: 7, 41: 9, 42: 5}\n",
            " - Total number of samples: 1300\n",
            "Client 6 (Miner 4, Local Client 3) data: {0: 1, 1: 2, 2: 14, 3: 8, 4: 178, 5: 105, 6: 80, 7: 2, 8: 236, 9: 25, 10: 80, 11: 7, 12: 15, 13: 1, 14: 12, 15: 5, 16: 37, 17: 36, 19: 22, 21: 4, 22: 1, 23: 4, 24: 4, 25: 4, 26: 54, 27: 1, 28: 8, 29: 34, 30: 35, 31: 41, 32: 3, 33: 6, 34: 3, 35: 20, 36: 3, 37: 4, 38: 19, 39: 1, 40: 10, 41: 11, 42: 2}\n",
            " - Total number of samples: 1138\n"
          ]
        }
      ],
      "source": [
        "def print_all_clients_class_distribution():\n",
        "    # Iterate through each miner/pool and its clients\n",
        "    for miner_id, miner_clients in enumerate(client_distributions):\n",
        "        # Iterate through each client in this miner's pool\n",
        "        for local_client_id, global_client_id in enumerate(miner_clients):\n",
        "            # Get dataset for the current client\n",
        "            client_dataset = flex_miners_data[miner_id][local_client_id]\n",
        "\n",
        "            # Extract labels\n",
        "            labels = [label for _, label in client_dataset]\n",
        "            unique, counts = np.unique(labels, return_counts=True)\n",
        "            count_dict = {int(k): int(v) for k, v in zip(unique, counts)}\n",
        "\n",
        "            print(f\"Client {global_client_id} (Miner {miner_id}, Local Client {local_client_id}) data: {count_dict}\")\n",
        "            print(f\" - Total number of samples: {sum(count_dict.values())}\")\n",
        "\n",
        "#print(client_distributions)\n",
        "print_all_clients_class_distribution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntD1a4Tia0Mv"
      },
      "source": [
        "###Poisoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-19T17:08:21.507313Z",
          "iopub.status.busy": "2025-06-19T17:08:21.507040Z",
          "iopub.status.idle": "2025-06-19T17:08:21.851694Z",
          "shell.execute_reply": "2025-06-19T17:08:21.851120Z",
          "shell.execute_reply.started": "2025-06-19T17:08:21.507268Z"
        },
        "id": "myKghB0-P0Xt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "target_label = 3\n",
        "\n",
        "@data_poisoner\n",
        "def poison_square(img, label, prob=POISONING_RATE):\n",
        "    if np.random.random() > prob:\n",
        "        return img, label\n",
        "    \n",
        "    arr = np.array(img)\n",
        "    new_arr = copy.deepcopy(arr)\n",
        "    \n",
        "    if DATASET_NAME == \"MNIST\":\n",
        "        new_arr[-1, -1] = 255\n",
        "        new_arr[-2, -1] = 255\n",
        "        new_arr[-1, -2] = 255\n",
        "        new_arr[-2, -2] = 255 \n",
        "\n",
        "    else:\n",
        "        new_arr[-POISON_PIXELS:, -POISON_PIXELS:, 0] = 255\n",
        "        new_arr[-POISON_PIXELS:, -POISON_PIXELS:, 1:] = 0\n",
        "\n",
        "\n",
        "    return Image.fromarray(new_arr), target_label\n",
        "\n",
        "\n",
        "k = 16   # Grid resolution\n",
        "s = 0.8  # Warping strength\n",
        "\n",
        "# Generate fixed noise pattern grid (trigger)\n",
        "control_points = torch.rand(k, k, 2) * 2 - 1\n",
        "control_points = control_points / torch.mean(torch.abs(control_points))\n",
        "control_points_reshaped = control_points.permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "noise_grid_base = control_points_reshaped \n",
        "\n",
        "@data_poisoner\n",
        "def poison_wanet(img, label, prob=POISONING_RATE):\n",
        "    if np.random.random() > prob:\n",
        "        return img, label\n",
        "\n",
        "    img_tensor = torchvision.transforms.functional.pil_to_tensor(img).float() / 255.0\n",
        "    current_img_h, current_img_w = img_tensor.shape[1], img_tensor.shape[2]\n",
        "\n",
        "    # Resize noise grid to current image size\n",
        "    noise_grid = torch.nn.functional.interpolate(\n",
        "        noise_grid_base,\n",
        "        size=(current_img_h, current_img_w),\n",
        "        mode='bicubic',\n",
        "        align_corners=True\n",
        "    ).squeeze(0).permute(1, 2, 0).unsqueeze(0)\n",
        "\n",
        "    # Create identity grid and dynamic grid \n",
        "    x_coords = torch.linspace(-1, 1, current_img_w)\n",
        "    y_coords = torch.linspace(-1, 1, current_img_h)\n",
        "    grid_x, grid_y = torch.meshgrid(x_coords, y_coords, indexing='xy')\n",
        "    identity_grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0)\n",
        "    dynamic_grid = torch.clamp(identity_grid + s * noise_grid / current_img_h, -1, 1)\n",
        "\n",
        "    # Apply warping\n",
        "    poisoned_tensor = torch.nn.functional.grid_sample(\n",
        "        img_tensor.unsqueeze(0), dynamic_grid, align_corners=True\n",
        "    ).squeeze(0)\n",
        "\n",
        "    poisoned_array = (poisoned_tensor * 255.0).clamp(0, 255).byte()\n",
        "    if DATASET_NAME == \"MNIST\":\n",
        "        poisoned_array = poisoned_array.squeeze(0).numpy()\n",
        "    else:\n",
        "        poisoned_array = poisoned_array.permute(1, 2, 0).numpy()\n",
        "\n",
        "    poisoned_img = Image.fromarray(poisoned_array)\n",
        "\n",
        "    return poisoned_img, target_label\n",
        "\n",
        "\n",
        "if TRIGGER == \"square\":\n",
        "    poison = poison_square\n",
        "elif TRIGGER == \"wanet\":\n",
        "    poison = poison_wanet\n",
        "\n",
        "poisoned_global_ids = list(range(N_POISONED))\n",
        "\n",
        "# Poison local datasets\n",
        "poisoned_clients_ids = []\n",
        "for n in range(N_POOLS):\n",
        "\n",
        "  to_poison_ids = [list(client_distributions[n]).index(gid) for gid in poisoned_global_ids if gid in client_distributions[n]]\n",
        "\n",
        "  flex_miners_data[n] = flex_miners_data[n].apply(poison, node_ids=to_poison_ids)\n",
        "  poisoned_clients_ids.append(to_poison_ids)\n",
        "\n",
        "#Convert test dataset\n",
        "poisoned_test_data = poison(test_data, prob=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_boosting_factor(poisoned_clients_ids):\n",
        "    \"\"\"\n",
        "    Calculates the boosting factor for the pool with the most poisoned clients.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Check if there are any pools with poisoned clients\n",
        "    if not any(poisoned_clients_ids):\n",
        "        return 1.0\n",
        "\n",
        "    # Find the pool with the most poisoned clients\n",
        "    num_poisoned_in_pools = [len(p) for p in poisoned_clients_ids]\n",
        "    most_poisoned_pool_idx = np.argmax(num_poisoned_in_pools)\n",
        "    \n",
        "    # Calculate the boosting factor\n",
        "    boosting_factor = len(client_distributions[most_poisoned_pool_idx]) / len(poisoned_clients_ids[most_poisoned_pool_idx])\n",
        "    \n",
        "    return boosting_factor\n",
        "\n",
        "\n",
        "DEFAULT_BOOSTING = calculate_boosting_factor(poisoned_clients_ids)\n",
        "\n",
        "# MNIST dataset is very sensitive to poisoning but guarantees with minimum 1\n",
        "if DATASET_NAME == \"MNIST\":\n",
        "    DEFAULT_BOOSTING = max(1, DEFAULT_BOOSTING / 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean sample:\n",
            "Label: 10\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample = 6\n",
        "print(f\"Clean sample:\")\n",
        "print(f\"Label:\", test_data[sample][1])\n",
        "img = test_data[sample][0]\n",
        "_ = plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "execution": {
          "iopub.execute_input": "2025-06-19T17:08:21.860086Z",
          "iopub.status.busy": "2025-06-19T17:08:21.859879Z",
          "iopub.status.idle": "2025-06-19T17:08:22.072412Z",
          "shell.execute_reply": "2025-06-19T17:08:22.071782Z",
          "shell.execute_reply.started": "2025-06-19T17:08:21.860063Z"
        },
        "id": "LD2IZHdNGUwg",
        "outputId": "1bf381ce-b451-43dc-cfc2-e35239df4480",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Poisoned sample:\n",
            "Label: 3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(f\"Poisoned sample:\")\n",
        "print(f\"Label:\", poisoned_test_data[sample][1])\n",
        "img = poisoned_test_data[sample][0]\n",
        "_ = plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1-pXQGqWZdh"
      },
      "source": [
        "###Rest of the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-19T17:08:22.073221Z",
          "iopub.status.busy": "2025-06-19T17:08:22.073044Z",
          "iopub.status.idle": "2025-06-19T17:08:22.092273Z",
          "shell.execute_reply": "2025-06-19T17:08:22.091579Z",
          "shell.execute_reply.started": "2025-06-19T17:08:22.073206Z"
        },
        "id": "LX4QZR4Nz0-j",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_model(num_classes=NUM_CLASSES, model_name=MODEL_NAME):\n",
        "\n",
        "    if model_name == \"resnet18\":\n",
        "        model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    elif model_name == \"mobilenet\":\n",
        "        model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
        "        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "    elif model_name == \"efficientnet\":\n",
        "        model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@init_server_model\n",
        "def build_server_model():\n",
        "    global server_flex_model\n",
        "\n",
        "    server_flex_model = FlexModel()\n",
        "\n",
        "    server_flex_model[\"model\"] = get_model()\n",
        "    # Required to store this for later stages of the FL training process\n",
        "    server_flex_model[\"criterion\"] = torch.nn.functional.cross_entropy\n",
        "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
        "    server_flex_model[\"optimizer_kwargs\"] = {\"lr\": LR}\n",
        "\n",
        "    return server_flex_model\n",
        "\n",
        "\n",
        "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
        "    train_dataset = client_data.to_torchvision_dataset(transform=data_transforms)\n",
        "    client_dataloader = DataLoader(train_dataset, batch_size=128)\n",
        "    model = client_flex_model[\"model\"]\n",
        "    optimizer = client_flex_model[\"optimizer_func\"](\n",
        "        model.parameters(), **client_flex_model[\"optimizer_kwargs\"]\n",
        "    )\n",
        "    model = model.train()\n",
        "    model = model.to(device)\n",
        "    criterion = client_flex_model[\"criterion\"]\n",
        "    for _ in range(LOCAL_EPOCHS):\n",
        "        for imgs, labels in client_dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(imgs)\n",
        "            loss = criterion(pred, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "@collect_clients_weights\n",
        "def get_clients_weights(client_flex_model: FlexModel):\n",
        "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
        "    server_dict = client_flex_model[\"server_model\"].state_dict()\n",
        "    dev = [weight_dict[name] for name in weight_dict][0].get_device()\n",
        "    dev = \"cpu\" if dev == -1 else \"cuda\"\n",
        "    return [\n",
        "        (weight_dict[name] - server_dict[name].to(dev)).type(torch.float)\n",
        "        for name in weight_dict\n",
        "    ]\n",
        "\n",
        "\n",
        "def apply_boosting(weight_list: list, coef: float):\n",
        "    set_tensorly_backend(weight_list)\n",
        "\n",
        "    n_layers = len(weight_list)\n",
        "    weights = []\n",
        "    for index_layer in range(n_layers):\n",
        "        context = tl.context(weight_list[index_layer])\n",
        "        w = weight_list[index_layer] * tl.tensor(coef, **context)\n",
        "        weights.append(w)\n",
        "    return weights\n",
        "\n",
        "\n",
        "@collect_clients_weights\n",
        "def get_poisoned_weights(client_flex_model: FlexModel):\n",
        "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
        "    server_dict = client_flex_model[\"server_model\"].state_dict()\n",
        "    dev = [weight_dict[name] for name in weight_dict][0].get_device()\n",
        "    dev = \"cpu\" if dev == -1 else \"cuda\"\n",
        "    return apply_boosting(\n",
        "        [\n",
        "            (weight_dict[name] - server_dict[name].to(dev)).type(torch.float)\n",
        "            for name in weight_dict\n",
        "        ],\n",
        "        DEFAULT_BOOSTING,\n",
        "    )\n",
        "\n",
        "\n",
        "@set_aggregated_weights\n",
        "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
        "    dev = aggregated_weights[0].get_device()\n",
        "    dev = \"cpu\" if dev == -1 else \"cuda\"\n",
        "    with torch.no_grad():\n",
        "        weight_dict = server_flex_model[\"model\"].state_dict()\n",
        "        for layer_key, new in zip(weight_dict, aggregated_weights):\n",
        "            weight_dict[layer_key].copy_(weight_dict[layer_key].to(dev) + new)\n",
        "\n",
        "\n",
        "@deploy_server_model\n",
        "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
        "    new_flex_model = FlexModel()\n",
        "    new_flex_model[\"model\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"server_model\"] = copy.deepcopy(server_flex_model[\"model\"])\n",
        "    new_flex_model[\"criterion\"] = copy.deepcopy(server_flex_model[\"criterion\"])\n",
        "    new_flex_model[\"optimizer_func\"] = copy.deepcopy(\n",
        "        server_flex_model[\"optimizer_func\"]\n",
        "    )\n",
        "    new_flex_model[\"optimizer_kwargs\"] = copy.deepcopy(\n",
        "        server_flex_model[\"optimizer_kwargs\"]\n",
        "    )\n",
        "    return new_flex_model\n",
        "\n",
        "\n",
        "def clean_up_models(clients: FlexPool):\n",
        "    import gc\n",
        "\n",
        "    clients.clients.map(lambda model, _: model.clear())\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "def obtain_metrics(server_flex_model: FlexModel, data: Dataset):\n",
        "    if data is None:\n",
        "        data = test_data\n",
        "    model = server_flex_model[\"model\"]\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    total_count = 0\n",
        "    model = model.to(device)\n",
        "    criterion = server_flex_model[\"criterion\"]\n",
        "    # get test data as a torchvision object\n",
        "    test_dataset = data.to_torchvision_dataset(transform=data_transforms)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset, batch_size=128, shuffle=False, pin_memory=False\n",
        "    )\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader:\n",
        "            total_count += target.size(0)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            losses.append(criterion(output, target).item())\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
        "\n",
        "    test_loss = sum(losses) / len(losses)\n",
        "    test_acc /= total_count\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "\n",
        "def obtain_accuracy(server_flex_model: FlexModel, data: Dataset):\n",
        "    return obtain_metrics(server_flex_model, data)[1]\n",
        "\n",
        "def obtain_backdoor_metrics(server_flex_model: FlexModel, _):\n",
        "    return obtain_metrics(server_flex_model, poisoned_test_data)\n",
        "\n",
        "\n",
        "def obtain_eval_metrics(server_flex_model: FlexModel, _):\n",
        "    return obtain_metrics(server_flex_model, test_data)\n",
        "\n",
        "\n",
        "def warmup(pool: FlexPool, poisoned_clients_ids):\n",
        "\n",
        "    clean_clients = pool.clients.select(\n",
        "        lambda client_id, _: client_id not in poisoned_clients_ids\n",
        "    )\n",
        "\n",
        "    #Just 3 epochs on benign clients to warm up the model\n",
        "    for i in tqdm(range(5), \"WARMUP BASE\"):\n",
        "        pool.servers.map(copy_server_model_to_clients, clean_clients)\n",
        "\n",
        "        clean_clients.map(train)\n",
        "\n",
        "        pool.aggregators.map(get_clients_weights, clean_clients)\n",
        "        pool.aggregators.map(agg_function)\n",
        "        pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
        "\n",
        "        clean_up_models(clean_clients)\n",
        "\n",
        "    acc = pool.servers.map(obtain_eval_metrics)\n",
        "    loss, accuracy = acc[0]\n",
        "    print(\"Warmup Accuracy:\")\n",
        "    print(f\"  - Loss     : {loss:.4f}\")\n",
        "    print(f\"  - Accuracy : {accuracy * 100:.2f}%\")\n",
        "\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train_round(pool: FlexPool, poisoned_clients_ids):\n",
        "\n",
        "    poisoned_clients = pool.clients.select(\n",
        "        lambda client_id, _: client_id in poisoned_clients_ids\n",
        "    )\n",
        "    clean_clients = pool.clients.select(\n",
        "        lambda client_id, _: client_id not in poisoned_clients_ids\n",
        "    )\n",
        "\n",
        "\n",
        "    pool.servers.map(copy_server_model_to_clients, clean_clients)\n",
        "    pool.servers.map(copy_server_model_to_clients, poisoned_clients)\n",
        "\n",
        "    clean_clients.map(train)\n",
        "    poisoned_clients.map(train)\n",
        "\n",
        "    pool.aggregators.map(get_clients_weights, clean_clients)\n",
        "    pool.aggregators.map(get_poisoned_weights, poisoned_clients)\n",
        "\n",
        "    pool.aggregators.map(agg_function)\n",
        "    pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
        "\n",
        "    clean_up_models(clean_clients)\n",
        "    clean_up_models(poisoned_clients)\n",
        "\n",
        "\n",
        "    main_acc = pool.servers.map(obtain_eval_metrics)\n",
        "    backdoor_acc = pool.servers.map(obtain_backdoor_metrics)\n",
        "\n",
        "    return main_acc, backdoor_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(a, b, eps=1e-10):\n",
        "    a = torch.from_numpy(a).float()\n",
        "    b = torch.from_numpy(b).float()\n",
        "    return torch.nn.functional.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0), dim=1, eps=eps).item()\n",
        "\n",
        "def get_model_vector(model):\n",
        "    # Uses only trainable parameters, used for gradients\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    return np.concatenate([p.detach().cpu().numpy().flatten() for p in params])\n",
        "\n",
        "\n",
        "def pos_consensus_mechanism(pools, previous_global_model):\n",
        "    \"\"\"\n",
        "    Each miner is compared pairwise against all others using gradients, highest average similarity is selected\n",
        "    \"\"\"\n",
        "\n",
        "    prev_global = get_model_vector(previous_global_model)\n",
        "\n",
        "    miner_grads = []\n",
        "    for pool in pools:\n",
        "        model = pool.aggregators._models['server']['model']\n",
        "        miner_vec = get_model_vector(model)\n",
        "        grad_vec = miner_vec - prev_global\n",
        "        miner_grads.append(grad_vec)\n",
        "\n",
        "    # Compute pairwise similarities all-to-all\n",
        "    n = len(miner_grads)\n",
        "    scores = []\n",
        "    for i in range(n):\n",
        "        sim_sum = 0.0\n",
        "        for j in range(n):\n",
        "            if i != j:\n",
        "                sim_sum += cosine_similarity(miner_grads[i], miner_grads[j])\n",
        "        avg_sim = sim_sum / (n - 1)\n",
        "        print(f\"[PoS] Pool {i} - Avg Pairwise Cosine Similarity: {avg_sim:.4f}\")\n",
        "        scores.append((i, avg_sim))\n",
        "\n",
        "    scores.sort(key=lambda x: x[1])\n",
        "    winner_idx, best_score = scores[-1]\n",
        "    print(f\"[PoS] Winner Pool: {winner_idx} Score: {best_score:.4f}\")\n",
        "\n",
        "    return winner_idx\n",
        "\n",
        "\n",
        "def update_blockchain(pools, blockchain, previous_global_model):\n",
        "    \"\"\"Update blockchain using PoS consensus and propagate winner's weights.\"\"\"\n",
        "    if previous_global_model is None:\n",
        "        # First model is random, select last pool as warmup\n",
        "        winner_idx = N_POOLS - 1\n",
        "        print(f\"[PoS] Winner Pool: {winner_idx} - Warmup random choice\")\n",
        "    else:\n",
        "        winner_idx = pos_consensus_mechanism(pools, previous_global_model)\n",
        "    \n",
        "    # Get winner weights and update blockchain\n",
        "    winner_model = copy.deepcopy(pools[winner_idx].aggregators._models['server']['model'])\n",
        "    winner_weights = winner_model.state_dict()\n",
        "    \n",
        "    new_block = BlockPoFL(weights=[param.cpu().numpy() for param in winner_weights.values()])\n",
        "    blockchain.add_block(new_block)\n",
        "    \n",
        "    # Propagate winner weights to other pools\n",
        "    for i, pool in enumerate(pools):\n",
        "        if i != winner_idx:\n",
        "            pool.aggregators._models['server']['model'].load_state_dict(winner_weights)\n",
        "    \n",
        "    return winner_idx, winner_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "execution": {
          "iopub.execute_input": "2025-06-19T17:08:22.115850Z",
          "iopub.status.busy": "2025-06-19T17:08:22.115631Z",
          "iopub.status.idle": "2025-06-19T18:42:44.150434Z",
          "shell.execute_reply": "2025-06-19T18:42:44.149862Z",
          "shell.execute_reply.started": "2025-06-19T17:08:22.115834Z"
        },
        "id": "SGNrf_6KvpbD",
        "outputId": "e1011aee-800f-49fa-ffeb-876df83d745f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***Proof-of-Similarity Experiment***\n",
            "  Model   : resnet18\n",
            "  Dataset : GTSRB\n",
            "  Non-IID : 0.5\n",
            "  Pools   : 5\n",
            "  Trigger : wanet\n",
            "\n",
            "========================================\n",
            "      POISONED CLIENTS PER POOL\n",
            "========================================\n",
            "Miner 0: 2\n",
            "Miner 1: 1\n",
            "Miner 2: 1\n",
            "Miner 3: 0\n",
            "Miner 4: 0\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "               WARMING UP\n",
            "========================================\n",
            "       *** [MINER 0] ***\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARMUP BASE: 100%|ââââââââââ| 5/5 [00:42<00:00,  8.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warmup Accuracy:\n",
            "  - Loss     : 1.7536\n",
            "  - Accuracy : 60.06%\n",
            "       *** [MINER 1] ***\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARMUP BASE:  80%|ââââââââ  | 4/5 [00:42<00:10, 10.65s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m       *** [MINER \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] ***\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m     pool = FlexPool.client_server_pool(flex_miners_data[n], build_server_model)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     acc = \u001b[43mwarmup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoisoned_clients_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     pools.append(pool)\n\u001b[32m     29\u001b[39m winner, global_model = update_blockchain(pools, blockchain, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 178\u001b[39m, in \u001b[36mwarmup\u001b[39m\u001b[34m(pool, poisoned_clients_ids)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mWARMUP BASE\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    176\u001b[39m     pool.servers.map(copy_server_model_to_clients, clean_clients)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[43mclean_clients\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     pool.aggregators.map(get_clients_weights, clean_clients)\n\u001b[32m    181\u001b[39m     pool.aggregators.map(fed_avg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/flex/pool/pool.py:135\u001b[39m, in \u001b[36mFlexPool.map\u001b[39m\u001b[34m(self, func, dst_pool, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Method used to send messages from one pool to another. The pool using\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03mthis method is the source pool, and it will send a message, apply a function,\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03mto the destination pool. If no destination pool is provided, then the function is applied\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    131\u001b[39m \u001b[33;03m    length of the returned values equals the number of actors in the source pool.\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dst_pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    134\u001b[39m     res = [\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_models\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._actors\n\u001b[32m    137\u001b[39m     ]\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m FlexPool.check_compatibility(\u001b[38;5;28mself\u001b[39m, dst_pool):\n\u001b[32m    139\u001b[39m     res = [\n\u001b[32m    140\u001b[39m         func(\u001b[38;5;28mself\u001b[39m._models.get(i), dst_pool._models, **kwargs)\n\u001b[32m    141\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._actors\n\u001b[32m    142\u001b[39m     ]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(client_flex_model, client_data)\u001b[39m\n\u001b[32m     37\u001b[39m optimizer = client_flex_model[\u001b[33m\"\u001b[39m\u001b[33moptimizer_func\u001b[39m\u001b[33m\"\u001b[39m](\n\u001b[32m     38\u001b[39m     model.parameters(), **client_flex_model[\u001b[33m\"\u001b[39m\u001b[33moptimizer_kwargs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     39\u001b[39m )\n\u001b[32m     40\u001b[39m model = model.train()\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m criterion = client_flex_model[\u001b[33m\"\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(LOCAL_EPOCHS):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "blockchain = BlockchainPoFL(BlockPoFL([])) \n",
        "pools = []\n",
        "\n",
        "print(f\"***Proof-of-Similarity Experiment***\")\n",
        "print(f\"  Model   : {MODEL_NAME}\")\n",
        "print(f\"  Dataset : {DATASET_NAME}\")\n",
        "print(f\"  Non-IID : {NON_IID_RATE}\")\n",
        "print(f\"  Pools   : {N_POOLS}\")\n",
        "print(f\"  Trigger : {TRIGGER}\")\n",
        "print(f\"  Aggregation: {AGG_FUNCTION}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"      POISONED CLIENTS PER POOL\")\n",
        "print(\"=\"*40)\n",
        "for i, poisoned in enumerate(poisoned_clients_ids):\n",
        "    print(f\"Miner {i}: {len(poisoned)}\")\n",
        "print(\"=\"*40 + \"\\n\")\n",
        "\n",
        "\n",
        "#WARMUP\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"               WARMING UP\")\n",
        "print(\"=\"*40)\n",
        "for n in range(N_POOLS):\n",
        "    print(f\"       *** [MINER {n}] ***\")\n",
        "    pool = FlexPool.client_server_pool(flex_miners_data[n], build_server_model)\n",
        "    acc = warmup(pool, poisoned_clients_ids[n])\n",
        "    pools.append(pool)\n",
        "\n",
        "winner, global_model = update_blockchain(pools, blockchain, None)\n",
        "\n",
        "\n",
        "#TRAINING ROUNDS\n",
        "for i in tqdm(range(N_ROUNDS), \"ROUNDS OF TRAINING\"):\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"            TRAINING ROUND {i}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Train all pools\n",
        "    for n in range(N_POOLS):\n",
        "        print(f\"\\n{'*'*30}\")\n",
        "        print(f\"       *** [MINER {n}] ***\")\n",
        "\n",
        "        metrics, backdoor_metrics = train_round(pools[n], poisoned_clients_ids[n])\n",
        "\n",
        "        loss, accuracy = metrics[0]\n",
        "        bd_loss, bd_accuracy = backdoor_metrics[0]\n",
        "\n",
        "        print(f\"Clean Data   :  Loss: {loss:.4f} | Acc: {accuracy * 100:.2f}%\")\n",
        "        print(f\"Backdoor Data:  Loss: {bd_loss:.4f} | Acc: {bd_accuracy * 100:.2f}%\")\n",
        "\n",
        "        print(f\"{'*'*30}\")\n",
        "\n",
        "    winner, global_model = update_blockchain(pools, blockchain, global_model)\n",
        "\n",
        "\n",
        "\n",
        "loss, accuracy = pools[winner].servers.map(obtain_eval_metrics)[0]\n",
        "bd_loss, bd_accuracy = pools[winner].servers.map(obtain_backdoor_metrics)[0]\n",
        "\n",
        "print(f\"{'='*30}\")\n",
        "print(f\" *** Final Model Metrics ***\")\n",
        "\n",
        "\n",
        "print(\"Clean Data:\")\n",
        "print(f\"  - Loss     : {loss:.4f}\")\n",
        "print(f\"  - Accuracy : {accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"Backdoor Data:\")\n",
        "print(f\"  - Loss     : {bd_loss:.4f}\")\n",
        "print(f\"  - Accuracy : {bd_accuracy * 100:.2f}%\")\n",
        "\n",
        "print(f\"{'='*30}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "jupyter-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
